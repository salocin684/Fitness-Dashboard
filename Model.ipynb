{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33a68f9fc8469f9a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-06T06:23:41.422847700Z",
     "start_time": "2023-10-06T06:23:41.397812Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Making the images to the same size with padding for the training set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a788d092ce9275d3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding completed for all images in the directory.\n"
     ]
    }
   ],
   "source": [
    "target_size = (224, 224)\n",
    "\n",
    "def pad_image(image_path, target_size):\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "\n",
    "    pad_width = max(0, target_size[0] - width)\n",
    "    pad_height = max(0, target_size[1] - height)\n",
    "    \n",
    "    left_padding = pad_width // 2\n",
    "    top_padding = pad_height // 2\n",
    "    #right_padding = pad_width - left_padding\n",
    "    #bottom_padding = pad_height - top_padding\n",
    "\n",
    "    padded_img = Image.new(img.mode, target_size, (225, 225, 225))\n",
    "    padded_img.paste(img, (left_padding, top_padding))\n",
    "\n",
    "    return padded_img\n",
    "\n",
    "\n",
    "input_directory = 'Data/train_v2/train/'\n",
    "output_directory = 'Data/train_v2/train_resize/'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "for image_file in glob.glob(os.path.join(input_directory, '*.jpg')):  # Adjust the file extension as needed\n",
    "    padded_image = pad_image(image_file, target_size)\n",
    "    filename = os.path.splitext(os.path.basename(image_file))[0]\n",
    "    output_path = os.path.join(output_directory, f'{filename}_padded.jpg')\n",
    "    padded_image.save(output_path)\n",
    "\n",
    "print(\"Padding completed for all images in the directory.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T07:28:10.989246100Z",
     "start_time": "2023-10-06T06:23:46.960696500Z"
    }
   },
   "id": "188e6c5bf9015c0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# one hot encode name label"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f7e17e7fafa7d08"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoded_labels = []\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(sparse_output=True)\n",
    "\n",
    "image_names = []\n",
    "label_names = []\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "data_reader = pd.read_csv('Data/written_name_train_v2.csv', chunksize=chunk_size)\n",
    "\n",
    "for chunk in data_reader:\n",
    "    image_names.extend(chunk['FILENAME'])\n",
    "    label_names.extend(chunk['IDENTITY'])\n",
    "\n",
    "    label_values = label_encoder.fit_transform(chunk['IDENTITY'])\n",
    "    onehot_labels = onehot_encoder.fit_transform(label_values.reshape(-1, 1))\n",
    "    dense_labels = onehot_labels.toarray()\n",
    "\n",
    "    for row in dense_labels:\n",
    "        decoded_label = label_encoder.inverse_transform([row.argmax()])\n",
    "        decoded_labels.append(decoded_label[0])\n",
    "\n",
    "for i, image_name in enumerate(image_names):\n",
    "    print(f\"Image Name: {image_name}, Original Label: {label_names[i]}, Decoded Label: {decoded_labels[i]}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T07:57:47.109889500Z",
     "start_time": "2023-10-06T07:57:11.626974600Z"
    }
   },
   "id": "6e7971923f1d6ebf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
